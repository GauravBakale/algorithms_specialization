{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strongly Connected Component (SCC)\n",
    "\n",
    "The file contains the edges of a directed graph. Vertices are labeled as positive integers from 1 to 875714. Every row indicates an edge, the vertex label in first column is the tail and the vertex label in second column is the head (recall the graph is directed, and the edges are directed from the first column vertex to the second column vertex). So for example, the 11th row looks liks : \"2 47646\". This just means that the vertex with label 2 has an outgoing edge to the vertex with label 47646\n",
    "\n",
    "Your task is to code up the algorithm from the video lectures for computing strongly connected components (SCCs), and to run this algorithm on the given graph.\n",
    "\n",
    "Output Format: You should output the sizes of the 5 largest SCCs in the given graph, in decreasing order of sizes, separated by commas (avoid any spaces). So if your algorithm computes the sizes of the five largest SCCs to be 500, 400, 300, 200 and 100, then your answer should be \"500,400,300,200,100\" (without the quotes). If your algorithm finds less than 5 SCCs, then write 0 for the remaining terms. Thus, if your algorithm computes only 3 SCCs whose sizes are 400, 300, and 100, then your answer should be \"400,300,100,0,0\" (without the quotes). (Note also that your answer should not have any spaces in it.)\n",
    "\n",
    "WARNING: This is the most challenging programming assignment of the course. Because of the size of the graph you may have to manage memory carefully. The best way to do this depends on your programming language and environment, and we strongly suggest that you exchange tips for doing this on the discussion forums.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/gauravbakale/projects/practice/Algorithms')\n",
    "\n",
    "from common.graphs import (\n",
    "    Vertex, \n",
    "    Edge, \n",
    "    Graph, \n",
    "    create_graph\n",
    ")\n",
    "from common.data_structures import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = \"a,b,c,d,e,f,g,h,i,j,k\"\n",
    "edges = \"a-c,b-a,c-b,b-j,b-k,j-i,j-h,i-h,h-k,k-j,j-e,e-f,f-g,g-e,c-d,d-f,d-e\"\n",
    "G = create_graph(\"G\", nodes, edges, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth First Search\n",
    "\n",
    "    Given,\n",
    "        - graph G \n",
    "        - node n(can be random to start the algo)\n",
    "        - Q = FIFO(queue), \n",
    "    1. assume all nodes unexplored\n",
    "    2. mark n explored\n",
    "    3. loop through all the adjacent nodes of n and if its not already explored or in the queue then add it to queue\n",
    "    4. loop through all the nodes in queue and its adjacent nodes until they are added to the explored list nodes list and the queue is empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def breadth_first_search(G: Graph, v: Vertex):\n",
    "    explored_vertexes = []\n",
    "    fifo_queue = Queue('FIFO')\n",
    "    fifo_queue.push(v)\n",
    "    while len(fifo_queue) > 0:\n",
    "        v = fifo_queue.pop()\n",
    "        for edge_name in G.edges:\n",
    "            edge = G.edges[edge_name]\n",
    "            if edge.source_vertex == v:\n",
    "                if edge.destination_vertex not in explored_vertexes and edge.destination_vertex not in fifo_queue.get():\n",
    "                    fifo_queue.push(edge.destination_vertex)\n",
    "        explored_vertexes.append(v)\n",
    "    \n",
    "    return explored_vertexes\n",
    "\n",
    "\n",
    "breadth_first_search(G, G.vertexes['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application : Shortest Path\n",
    "    \n",
    "    Since we explore nodes in layers if the node n is in i_th layer from s, then the distance from s to n is i. This is also the shortest path.\n",
    "    Proof: If lets say the distance from s to n given by bfs is 4. Now, it can't be less than 3 because if that was the case then node n would have been explored in the 3rd layer itself.\n",
    "\n",
    "    This is an additional property of BFS. \n",
    "\n",
    "    __Proof__ : Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bread_first_search_with_shortest_distance(G: Graph, s: Vertex, n: Vertex):\n",
    "    explored_vertexes = []\n",
    "    fifo_queue = Queue('FIFO')\n",
    "    fifo_queue.push(s)\n",
    "    distance = {}\n",
    "    distance[s] = 0\n",
    "    while len(fifo_queue) > 0:\n",
    "        v = fifo_queue.pop()\n",
    "        for edge_name in G.edges:\n",
    "            edge = G.edges[edge_name]\n",
    "            if edge.source_vertex == v:\n",
    "                if edge.destination_vertex not in explored_vertexes and edge.destination_vertex not in fifo_queue.get():\n",
    "                    fifo_queue.push(edge.destination_vertex)\n",
    "                    distance[edge.destination_vertex] = distance[v] + 1\n",
    "\n",
    "        explored_vertexes.append(v)\n",
    "    \n",
    "    return distance[n]\n",
    "\n",
    "bread_first_search_with_shortest_distance(G, G.vertexes['a'], G.vertexes['h'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth First Search\n",
    "\n",
    "    Depth first search works on basis of aggresive exploring. For example, if we start with node s, then we got to an adjacent node of s, lets say r, then we go to one of the adjacent nodes of r, lets say c. We backtrack from c only if c is already explored or is a end node. Otherwise we go to the next adjacent node of c.\n",
    "\n",
    "It can either be implemented same as bfs but instead of using FIFO use LIFO. (OR) we can use recursive method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(G: Graph, s: Vertex):\n",
    "    Q = Queue('LIFO')\n",
    "    explored_vertexes = []\n",
    "    Q.push(s)\n",
    "    while len(Q):\n",
    "        v = Q.pop()\n",
    "        Q.push(v)\n",
    "        explored_vertexes.append(v)\n",
    "        explored_vertexes_len = len(explored_vertexes)\n",
    "        for edge_name in G.all_edges:\n",
    "            edge = G.all_edges[edge_name]\n",
    "            if edge.source_vertex == v:\n",
    "                if edge.destination_vertex not in explored_vertexes and edge.destination_vertex not in Q.get():\n",
    "                    Q.push(edge.destination_vertex)\n",
    "                    break\n",
    "        if explored_vertexes_len == len(explored_vertexes):\n",
    "            Q.pop()\n",
    "        \n",
    "\n",
    "\n",
    "depth_first_search(G,G.vertexes['a'])    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fifo_queue.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexes = []\n",
    "edges = []\n",
    "with open('SCC_small.txt','r') as file:\n",
    "    for row in file:\n",
    "        \n",
    "        row = row.split()\n",
    "        \n",
    "        # add the vertexes\n",
    "        if row[0] not in vertexes: vertexes.append(row[0])\n",
    "        if row[1] not in vertexes: vertexes.append(row[1])\n",
    "\n",
    "        # add the edges\n",
    "        edge = f\"{row[0]}-{row[1]}\"\n",
    "        if edge not in edges: edges.append(edge)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rough",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
